{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory:  /Users/saeed/Documents/GitHub/ireland_res_chatbot\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from subs.db_connections import connetc_to_irish_db\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Check current working directory.\n",
    "print(\"Current Working Directory: \", os.getcwd())\n",
    "\n",
    "\n",
    "# #llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "db = connetc_to_irish_db()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an agent designed to interact with a SQL database.\\n        Given an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\\n        Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\\n        You can order the results by a relevant column to return the most interesting examples in the database.\\n        Query for the relevant columns needed to answer the question comprehensively. \\n        In cases where calculations or comparisons across multiple sectors (such as IE and NI) are required,\\n        ensure to include all necessary columns for these calculations. Prioritize efficiency and relevance in your queries.\\n        You have access to tools for interacting with the database.\\n        Only use the given tools. Only use the information returned by the tools to construct your final answer.\\n\\n        You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n\\n        DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n\\n        If the question does not seem related to the database, just return \"I don\\'t know\" as the answer.\\n\\n        If the question seeks column names, the entire dataset, or appears designed to extract the dataset indirectly, respond with \\'I cannot share these details; however, feel free to ask a specific query.\\n        \\n        Here are some examples of user inputs and their corresponding SQL queries:'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prefix(\"chain_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SemanticSimilarityExampleSelector(vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1236ba3e0>, k=5, example_keys=None, input_keys=['input'], vectorstore_kwargs=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector(\"chain_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['dialect', 'top_k'], example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1236b8b80>, k=5, example_keys=None, input_keys=['input'], vectorstore_kwargs=None), example_prompt=PromptTemplate(input_variables=['input', 'query'], template='User input: {input}\\nSQL query: {query}'), suffix='', prefix='You are an agent designed to interact with a SQL database.\\n        Given an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\\n        Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\\n        You can order the results by a relevant column to return the most interesting examples in the database.\\n        Query for the relevant columns needed to answer the question comprehensively. \\n        In cases where calculations or comparisons across multiple sectors (such as IE and NI) are required,\\n        ensure to include all necessary columns for these calculations. Prioritize efficiency and relevance in your queries.\\n        You have access to tools for interacting with the database.\\n        Only use the given tools. Only use the information returned by the tools to construct your final answer.\\n\\n        You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n\\n        DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n\\n        If the question does not seem related to the database, just return \"I don\\'t know\" as the answer.\\n\\n        If the question seeks column names, the entire dataset, or appears designed to extract the dataset indirectly, respond with \\'I cannot share these details; however, feel free to ask a specific query.\\n        \\n        Here are some examples of user inputs and their corresponding SQL queries:')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt(\"chain_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate(\n",
    "        prompt=few_shot_prompt(\"chain_1\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=FewShotPromptTemplate(input_variables=['dialect', 'top_k'], example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1236ec670>, k=5, example_keys=None, input_keys=['input'], vectorstore_kwargs=None), example_prompt=PromptTemplate(input_variables=['input', 'query'], template='User input: {input}\\nSQL query: {query}'), suffix='', prefix='You are an agent designed to interact with a SQL database.\\n        Given an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\\n        Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\\n        You can order the results by a relevant column to return the most interesting examples in the database.\\n        Query for the relevant columns needed to answer the question comprehensively. \\n        In cases where calculations or comparisons across multiple sectors (such as IE and NI) are required,\\n        ensure to include all necessary columns for these calculations. Prioritize efficiency and relevance in your queries.\\n        You have access to tools for interacting with the database.\\n        Only use the given tools. Only use the information returned by the tools to construct your final answer.\\n\\n        You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\\n\\n        DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\\n\\n        If the question does not seem related to the database, just return \"I don\\'t know\" as the answer.\\n\\n        If the question seeks column names, the entire dataset, or appears designed to extract the dataset indirectly, respond with \\'I cannot share these details; however, feel free to ask a specific query.\\n        \\n        Here are some examples of user inputs and their corresponding SQL queries:'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "input_query={\n",
    "        \"input\": \"How many years are there\",\n",
    "        \"top_k\": 5,\n",
    "        \"dialect\": \"SQLite\",\n",
    "        \"agent_scratchpad\": [],\n",
    "    }\n",
    "\n",
    "ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            system_message_prompt,\n",
    "            (\"human\", input_query),\n",
    "            MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msubs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Example formatted prompt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m prompt_val \u001b[38;5;241m=\u001b[39m \u001b[43minvoke_full_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchain_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow many years are there\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdialect\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSQLite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magent_scratchpad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/ireland_res_chatbot/subs/prompts.py:172\u001b[0m, in \u001b[0;36minvoke_full_prompt\u001b[0;34m(chain_id, input_query)\u001b[0m\n\u001b[1;32m    167\u001b[0m system_message_prompt \u001b[38;5;241m=\u001b[39m SystemMessagePromptTemplate(\n\u001b[1;32m    168\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mfew_shot_prompt(chain_id)\n\u001b[1;32m    169\u001b[0m )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Construct the full prompt template with the system message, the user's query, and a placeholder for the agent's scratchpad.\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mChatPromptTemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_message_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_query\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMessagesPlaceholder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magent_scratchpad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m full_prompt\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/prompts/chat.py:788\u001b[0m, in \u001b[0;36mChatPromptTemplate.from_messages\u001b[0;34m(cls, messages)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_messages\u001b[39m(\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    752\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m    753\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m    754\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \n\u001b[1;32m    756\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;124;03m        a chat prompt template\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m [_convert_to_message(message) \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[1;32m    791\u001b[0m     input_vars: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/prompts/chat.py:788\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_messages\u001b[39m(\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    752\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m    753\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m    754\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \n\u001b[1;32m    756\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;124;03m        a chat prompt template\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m [\u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages]\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[1;32m    791\u001b[0m     input_vars: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/prompts/chat.py:992\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    990\u001b[0m message_type_str, template \u001b[38;5;241m=\u001b[39m message\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message_type_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 992\u001b[0m     _message \u001b[38;5;241m=\u001b[39m \u001b[43m_create_template_from_message_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_type_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    994\u001b[0m     _message \u001b[38;5;241m=\u001b[39m message_type_str(\n\u001b[1;32m    995\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(cast(\u001b[38;5;28mstr\u001b[39m, template))\n\u001b[1;32m    996\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/prompts/chat.py:945\u001b[0m, in \u001b[0;36m_create_template_from_message_type\u001b[0;34m(message_type, template)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a message prompt template from a message type and template string.\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \n\u001b[1;32m    937\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;124;03m    a message prompt template of the appropriate type.\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 945\u001b[0m     message: BaseMessagePromptTemplate \u001b[38;5;241m=\u001b[39m \u001b[43mHumanMessagePromptTemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemplate\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m message_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    949\u001b[0m     message \u001b[38;5;241m=\u001b[39m AIMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(cast(\u001b[38;5;28mstr\u001b[39m, template))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/prompts/chat.py:389\u001b[0m, in \u001b[0;36m_StringImageMessagePromptTemplate.from_template\u001b[0;34m(cls, template, template_format, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(prompt\u001b[38;5;241m=\u001b[39mprompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from subs.prompts import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example formatted prompt\n",
    "prompt_val = invoke_full_prompt(chain_id=\"chain_1\", input_query=\n",
    "    {\n",
    "        \"input\": \"How many years are there\",\n",
    "        \"top_k\": 5,\n",
    "        \"dialect\": \"SQLite\",\n",
    "        \"agent_scratchpad\": [],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
