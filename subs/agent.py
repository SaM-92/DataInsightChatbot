from langchain_community.agent_toolkits import create_sql_agent
from subs.db_connections import connect_to_irish_db
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os
from subs.prompts import (
    prompt_template_creator,
    invoke_full_prompt,
    python_plotter_prompt_sys,
    python_plotter_prompt_user,
)

from langchain.chains import LLMChain, SimpleSequentialChain
from langchain.schema import SystemMessage, HumanMessage
import streamlit as st

load_dotenv()
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]


# Function to initialize the ChatOpenAI model
def init_llm(api_key: str) -> ChatOpenAI:
    """
    Initialize and return a ChatOpenAI language model instance.

    Returns:
        ChatOpenAI: An instance of the ChatOpenAI class.
    """
    # return ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    return ChatOpenAI(model="gpt-4-turbo", temperature=0, api_key=api_key)


def sql_agent(prompt):
    """
    Creates and returns a SQL agent configured with a language model, database connection,
    and the provided prompt template.

    Args:
        prompt: The prompt template to be used by the SQL agent.

    Returns:
        An instance of the configured SQL agent.
    """

    # Initialize the language model and database connection
    llm = init_llm(api_key=OPENAI_API_KEY)
    db = connect_to_irish_db(cloud=True)

    agent = create_sql_agent(
        llm=llm,
        db=db,
        prompt=prompt,
        verbose=True,
        agent_type="openai-tools",
    )
    return agent


def agent_plot_and_response(chain_id: str) -> LLMChain:
    """
    Prepares an LLM chain with a specific prompt template, based on the given chain ID.

    Args:
        chain_id (str): The identifier for selecting the appropriate chain configuration and prompt template.

    Returns:
        LLMChain: An instance of LLMChain configured with the initialized LLM and the generated prompt template.
    """
    llm = init_llm(api_key=OPENAI_API_KEY)
    prompt = prompt_template_creator(chain_id)
    agent = LLMChain(llm=llm, prompt=prompt)
    return agent


def configure_sequential_chain(
    chain_id_sql: str = "chain_1",
    # chain_id_response_plot: str = "chain_2",
    chain_id_response_python: str = "chain_python_coder",
) -> SimpleSequentialChain:
    """
    Configures and returns a sequential chain composed of an SQL agent chain and a plot-and-response agent chain.

    Args:
        chain_id_sql (str): The identifier for selecting the appropriate SQL chain configuration.
                            Defaults to "chain_1".
        chain_id_response_plot (str): The identifier for the chain that handles plotting and responses.
                                      Defaults to "chain_2".
        chain_id_response_python (str) : The identifier for the chain that handles python code based on sql agent response
                                  Defaults to "chain_python_coder".

    Returns:
        SimpleSequentialChain: A sequential chain that first executes SQL queries and then processes plotting and responses.
    """
    # Invoke the full prompt for the SQL chain using the provided SQL chain ID
    prompt_for_sql = invoke_full_prompt(chain_id=chain_id_sql)

    # Create the SQL agent chain with the generated prompt
    chain_sql = sql_agent(prompt=prompt_for_sql)

    # # Create the plot-and-response agent chain using the provided response and plot chain ID
    # chain_response_plot = agent_plot_and_response(chain_id=chain_id_response_plot)

    # Send the query response and get an executable Python code
    chain_response_plot = agent_plot_and_response(chain_id=chain_id_response_python)

    # # Combine the SQL agent chain and the plot-and-response agent chain into a sequential chain
    chain_final = SimpleSequentialChain(
        chains=[chain_sql, chain_response_plot], verbose=True
    )

    # Return the configured sequential chain
    return chain_final


def agent_plot_and_response_v2(user_query: str, plot_data: str) -> LLMChain:
    """
    Prepares an LLM chain to generate Python plotting scripts using matplotlib.

    Args:
        user_query (str): The user query that requests specific chart types.
        plot_data (str): The dataset to be visualized.

    Returns:
        str: The Python script generated by the LLM.
    """
    # Initialize the chat model
    llm = init_llm(api_key=OPENAI_API_KEY)

    # Define the system message content
    system_message = SystemMessage(content=python_plotter_prompt_sys())

    # Create the user prompt
    user_prompt = python_plotter_prompt_user(user_query=user_query, plot_data=plot_data)

    # Create a message list to pass to the LLM
    messages = [system_message, HumanMessage(content=user_prompt)]

    # Get the response from the LLM
    response = llm(messages)

    # Extract the generated code from the response
    return response.content.strip()


# Define the function that wraps both SQL and plot generation
def generate_sql_and_plot(
    chain_id_sql: str, chain_id_response_plot: str, user_query: str
) -> tuple:
    """
    Generates SQL output and a plot script based on a user query using two different chains.

    Args:
        chain_id_sql (str): Chain ID for the SQL agent prompt.
        chain_id_response_plot (str): Chain ID for the response/plotting agent prompt.
        user_query (str): User's query to pass to the chains.

    Returns:
        tuple: Contains the SQL chain output and the final plot script.
    """
    # Step 1: Invoke the full prompt for the SQL chain using the provided chain ID
    prompt_for_sql = invoke_full_prompt(chain_id=chain_id_sql)
    chain_sql = sql_agent(prompt=prompt_for_sql)

    # Step 2: Execute the SQL chain with the provided user query
    sql_output = chain_sql.run(user_query)

    st.write("âœ… We got the results, now we are preparing the figure for you!")

    # Step 3: Create the response and plot agent chain using the SQL output and user query
    plot_output = agent_plot_and_response_v2(
        user_query=user_query, plot_data=sql_output
    )

    # Return both outputs as a tuple
    return sql_output, plot_output
